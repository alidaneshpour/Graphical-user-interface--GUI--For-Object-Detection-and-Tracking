{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI (Graphical User Interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, filedialog, messagebox\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageTk\n",
    "from threading import Thread\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def play_video(video_path, canvas, label, tracker=None, detections=None, model_type=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    canvas_width = canvas.winfo_width()\n",
    "    canvas_height = canvas.winfo_height()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if tracker:\n",
    "            success, bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, \"Tracking\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        elif detections and model_type == \"mask_rcnn\":\n",
    "            for i, (box, score) in enumerate(detections):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 165, 0), 2)\n",
    "                text = f\"ID:{i} (Conf: {score:.2f})\"\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 165, 0), 2)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "        frame_image = ImageTk.PhotoImage(Image.fromarray(frame))\n",
    "\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=frame_image)\n",
    "        label.image = frame_image\n",
    "        label.update()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def play_multi_video(video_path, canvas, label, trackers=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    canvas_width = canvas.winfo_width()\n",
    "    canvas_height = canvas.winfo_height()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if trackers:\n",
    "            for tracker in trackers:\n",
    "                success, bbox = tracker.update(frame)\n",
    "                if success:\n",
    "                    x, y, w, h = map(int, bbox)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "        frame_image = ImageTk.PhotoImage(Image.fromarray(frame))\n",
    "\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=frame_image)\n",
    "        label.image = frame_image\n",
    "        label.update()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "# Function to update the detection frame based on the checkbox state\n",
    "def update_detection_frame(frame, detections, model_type):\n",
    "    for i, detection in enumerate(detections):\n",
    "        if model_type == \"mask_rcnn\":\n",
    "            # Mask R-CNN detections: (box, score)\n",
    "            box, score = detection\n",
    "            x1, y1, x2, y2 = map(int, box)  # Convert to integers\n",
    "        elif model_type == \"yolov5\":\n",
    "            # YOLOv5 detections: [x1, y1, x2, y2, conf, cls]\n",
    "            x1, y1, x2, y2, conf, _ = map(float, detection[:6])  # Ensure all values are floats\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])  # Convert to integers\n",
    "            score = conf  # Use confidence score as score\n",
    "        elif model_type == \"yolov8\":\n",
    "            # YOLOv8 detections: (box, conf, cls)\n",
    "            box, conf, _ = detection\n",
    "            x1, y1, x2, y2 = map(int, box)  # Convert to integers\n",
    "            score = conf  # Confidence score\n",
    "\n",
    "        # Draw the bounding box\n",
    "        if model_type == \"mask_rcnn\":\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)  # Orange box\n",
    "        elif model_type == \"yolov5\":\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)  # Orange box\n",
    "        elif model_type == \"yolov8\":\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Orange box\n",
    "\n",
    "\n",
    "        # Add the text (ID and optionally confidence score)\n",
    "        if model_type == \"mask_rcnn\":\n",
    "            text = f\"ID:{i}\" if not show_confidence_var.get() else f\"ID:{i} (Conf: {score:.2f})\"\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)\n",
    "        elif model_type == \"yolov5\":\n",
    "            text = f\"ID:{i}\" if not show_confidence_var.get() else f\"ID:{i} (Conf: {score:.2f})\"\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "        elif model_type == \"yolov8\":\n",
    "            text = f\"ID:{i}\" if not show_confidence_var.get() else f\"ID:{i} (Conf: {score:.2f})\"\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# confidence score search box \n",
    "def validate_confidence_input(P):\n",
    "    \"\"\"Validate the input to ensure it's a number between 0-100\"\"\"\n",
    "    if P == \"\":  # Allow empty field\n",
    "        return True\n",
    "    try:\n",
    "        value = float(P)\n",
    "        return 0 <= value <= 100\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def on_confidence_change(event=None):\n",
    "    \"\"\"Handle confidence score changes\"\"\"\n",
    "    try:\n",
    "        value = float(confidence_entry.get())\n",
    "        if 0 <= value <= 100:\n",
    "            # Here you can add what happens when a valid confidence score is entered\n",
    "            print(f\"Confidence score set to: {value}%\")\n",
    "            # confidence_label.config(text=f\"Current confidence: {value}%\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Invalid Input\", \"Please enter a number between 0 and 100\")\n",
    "            confidence_entry.delete(0, tk.END)\n",
    "    except ValueError:\n",
    "        if confidence_entry.get() != \"\":  # Only show error if field isn't empty\n",
    "            messagebox.showwarning(\"Invalid Input\", \"Please enter a valid number\")\n",
    "            confidence_entry.delete(0, tk.END)\n",
    "\n",
    "#mask_rcnn\n",
    "def process_first_frame_mask_rcnn(video_path, detection_canvas, detection_label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    input_frame = transform(frame).unsqueeze(0)\n",
    "\n",
    "    # Get the user-defined confidence threshold\n",
    "    confidence_threshold = get_confidence_threshold()  # This gets the value from the input box\n",
    "\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_frame)\n",
    "\n",
    "    pred_boxes = predictions[0][\"boxes\"].cpu().numpy()\n",
    "    pred_scores = predictions[0][\"scores\"].cpu().numpy()\n",
    "\n",
    "    # Use the dynamic confidence threshold\n",
    "    filtered_detections = [\n",
    "        (box, score) for box, score in zip(pred_boxes, pred_scores) if score > confidence_threshold\n",
    "    ]\n",
    "\n",
    "    frame = update_detection_frame(frame, filtered_detections, \"mask_rcnn\")\n",
    "\n",
    "    detected_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detected_frame = cv2.resize(detected_frame, (detection_canvas.winfo_width(), detection_canvas.winfo_height()))\n",
    "    detected_frame = Image.fromarray(detected_frame)\n",
    "    detected_frame = ImageTk.PhotoImage(detected_frame)\n",
    "\n",
    "    detection_canvas.create_image(0, 0, anchor=tk.NW, image=detected_frame)\n",
    "    detection_label.image = detected_frame\n",
    "\n",
    "    cap.release()\n",
    "    return filtered_detections\n",
    "\n",
    "#yolo5 \n",
    "def process_first_frame_yolov5(video_path, detection_canvas, detection_label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Get the user-defined confidence threshold\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    results = model(frame)\n",
    "    detections = results.pred[0]\n",
    "\n",
    "    # Use the dynamic confidence threshold\n",
    "    filtered_detections = [d for d in detections if d[4] > confidence_threshold]\n",
    "\n",
    "    frame = update_detection_frame(frame, filtered_detections, \"yolov5\")\n",
    "\n",
    "    detected_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detected_frame = cv2.resize(detected_frame, (detection_canvas.winfo_width(), detection_canvas.winfo_height()))\n",
    "    detected_frame = Image.fromarray(detected_frame)\n",
    "    detected_frame = ImageTk.PhotoImage(detected_frame)\n",
    "\n",
    "    detection_canvas.create_image(0, 0, anchor=tk.NW, image=detected_frame)\n",
    "    detection_label.image = detected_frame\n",
    "\n",
    "    cap.release()\n",
    "    return filtered_detections\n",
    "\n",
    "#yolo8\n",
    "def process_first_frame_yolov8(video_path, detection_canvas, detection_label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Get the user-defined confidence threshold\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "\n",
    "    model = YOLO('yolov8s.pt')\n",
    "    results = model(frame)\n",
    "    detections = results[0].boxes\n",
    "    boxes = detections.xyxy.cpu().numpy()\n",
    "    confs = detections.conf.cpu().numpy()\n",
    "    classes = detections.cls.cpu().numpy()\n",
    "\n",
    "    # Use the dynamic confidence threshold\n",
    "    filtered_detections = [(box, conf, cls) for box, conf, cls in zip(boxes, confs, classes) \n",
    "                          if conf > confidence_threshold]\n",
    "\n",
    "    frame = update_detection_frame(frame, filtered_detections, \"yolov8\")\n",
    "\n",
    "    detected_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detected_frame = cv2.resize(detected_frame, (detection_canvas.winfo_width(), detection_canvas.winfo_height()))\n",
    "    detected_frame = Image.fromarray(detected_frame)\n",
    "    detected_frame = ImageTk.PhotoImage(detected_frame)\n",
    "\n",
    "    detection_canvas.create_image(0, 0, anchor=tk.NW, image=detected_frame)\n",
    "    detection_label.image = detected_frame\n",
    "\n",
    "    cap.release()\n",
    "    return filtered_detections\n",
    "\n",
    "def upload_video():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4 *.avi *.mov\")])\n",
    "    if file_path:\n",
    "        input_path_var.set(file_path)\n",
    "        display_video(file_path, input_canvas, input_label)\n",
    "\n",
    "\n",
    "# Mask R-CNN button function\n",
    "def process_with_mask_rcnn():\n",
    "    input_path = input_path_var.get()\n",
    "    if not input_path:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a video first.\")\n",
    "        return\n",
    "\n",
    "    # Get current confidence threshold from input\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "    \n",
    "    if confidence_threshold is None:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid confidence threshold (0-100%).\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        global detections, current_model\n",
    "        detections = process_first_frame_mask_rcnn(input_path, detection_canvas, detection_label)\n",
    "        current_model = \"mask_rcnn\"\n",
    "        \n",
    "        # Update the UI to show current confidence threshold being used\n",
    "        status_message = f\"Mask R-CNN processing complete (Confidence Threshold: {confidence_threshold:.1%})\"\n",
    "        # Assuming you have a status label in your UI\n",
    "        if 'status_label' in globals():\n",
    "            status_label.config(text=status_message)\n",
    "            \n",
    "        return detections\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error processing video: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Add this function to update detections when confidence threshold changes\n",
    "def update_mask_rcnn_detections():\n",
    "    if current_model == \"mask_rcnn\" and detections:\n",
    "        new_confidence = get_confidence_threshold()\n",
    "        # Reprocess the current frame with new confidence threshold\n",
    "        process_with_mask_rcnn()\n",
    "\n",
    "# yolo5\n",
    "def process_with_yolov5():\n",
    "    input_path = input_path_var.get()\n",
    "    if not input_path:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a video first.\")\n",
    "        return\n",
    "\n",
    "    # Get current confidence threshold from input\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "    \n",
    "    if confidence_threshold is None:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid confidence threshold (0-100%).\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        global detections, current_model\n",
    "        detections = process_first_frame_yolov5(input_path, detection_canvas, detection_label)\n",
    "        current_model = \"yolov5\"\n",
    "        \n",
    "        # Update the UI to show current confidence threshold being used\n",
    "        status_message = f\"YOLOv5 processing complete (Confidence Threshold: {confidence_threshold:.1%})\"\n",
    "        # Assuming you have a status label in your UI\n",
    "        if 'status_label' in globals():\n",
    "            status_label.config(text=status_message)\n",
    "            \n",
    "        return detections\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error processing video: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def update_yolov5_detections():\n",
    "    if current_model == \"yolov5\" and detections:\n",
    "        new_confidence = get_confidence_threshold()\n",
    "        # Reprocess the current frame with new confidence threshold\n",
    "        process_with_yolov5()\n",
    "\n",
    "# Update the apply button command to handle both models\n",
    "def update_detections():\n",
    "    if current_model == \"yolov5\":\n",
    "        update_yolov5_detections()\n",
    "    elif current_model == \"mask_rcnn\":\n",
    "        update_mask_rcnn_detections()\n",
    "\n",
    "# yolo8\n",
    "def process_with_yolov8():\n",
    "    input_path = input_path_var.get()\n",
    "    if not input_path:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a video first.\")\n",
    "        return\n",
    "\n",
    "    # Get current confidence threshold from input\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "    \n",
    "    if confidence_threshold is None:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid confidence threshold (0-100%).\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        global detections, current_model\n",
    "        detections = process_first_frame_yolov8(input_path, detection_canvas, detection_label)\n",
    "        current_model = \"yolov8\"\n",
    "        \n",
    "        # Update the UI to show current confidence threshold being used\n",
    "        status_message = f\"YOLOv8 processing complete (Confidence Threshold: {confidence_threshold:.1%})\"\n",
    "        # Assuming you have a status label in your UI\n",
    "        if 'status_label' in globals():\n",
    "            status_label.config(text=status_message)\n",
    "            \n",
    "        return detections\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error processing video: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def update_yolov8_detections():\n",
    "    if current_model == \"yolov8\" and detections:\n",
    "        new_confidence = get_confidence_threshold()\n",
    "        # Reprocess the current frame with new confidence threshold\n",
    "        process_with_yolov8()\n",
    "\n",
    "#track object def\n",
    "def track_object():\n",
    "    input_path = input_path_var.get()\n",
    "    if not input_path:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a video and process it first.\")\n",
    "        return\n",
    "\n",
    "    if detections is None or len(detections) == 0:\n",
    "        messagebox.showerror(\"Error\", \"No detections to track. Run detection first.\")\n",
    "        return\n",
    "\n",
    "    # Get current confidence threshold\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "\n",
    "    # Filter detections based on current model and confidence threshold\n",
    "    if current_model == \"yolov5\":\n",
    "        valid_detections = [d for d in detections if d[4] > confidence_threshold]\n",
    "        confidence_scores = [d[4] for d in valid_detections]\n",
    "    elif current_model == \"yolov8\":\n",
    "        valid_detections = [(box, conf, cls) for box, conf, cls in detections if conf > confidence_threshold]\n",
    "        confidence_scores = [conf for _, conf, _ in valid_detections]\n",
    "    elif current_model == \"mask_rcnn\":\n",
    "        valid_detections = [(box, score) for box, score in detections if score > confidence_threshold]\n",
    "        confidence_scores = [score for _, score in valid_detections]\n",
    "\n",
    "    if not valid_detections:\n",
    "        messagebox.showerror(\"Error\", f\"No valid detections above confidence threshold of {confidence_threshold:.1%}\")\n",
    "        return\n",
    "\n",
    "    # Sort detections by confidence score in descending order to maintain consistent ordering\n",
    "    valid_detections = [x for _, x in sorted(zip(confidence_scores, valid_detections), reverse=True)]\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Display confidence scores for each object\n",
    "    confidence_info = \"\\n\".join([f\"Object {i}: {confidence_scores[i]:.1%}\" \n",
    "                                for i in range(len(valid_detections))])\n",
    "    \n",
    "    object_id = simpledialog.askinteger(\"Select Object\", \n",
    "                                      f\"Enter object ID (0 to {len(valid_detections) - 1})\\n\\n\"\n",
    "                                      f\"Detected objects (sorted by confidence):\\n{confidence_info}\")\n",
    "\n",
    "    if  object_id < 0 or object_id >= len(valid_detections):\n",
    "        messagebox.showerror(\"Error\", \"Invalid object ID selected.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Extract bounding box based on model type\n",
    "    if current_model == \"yolov5\":\n",
    "        x1, y1, x2, y2, _, _ = valid_detections[object_id].tolist()\n",
    "    elif current_model == \"yolov8\":\n",
    "        box, _, _ = valid_detections[object_id]\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "    elif current_model == \"mask_rcnn\":\n",
    "        box, _ = valid_detections[object_id]\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "    bbox = (int(x1), int(y1), int(x2 - x1), int(y2 - y1))\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "\n",
    "    display_video(input_path, output_canvas, output_label, tracker)\n",
    "    cap.release()\n",
    "\n",
    "def display_video(video_path, canvas, label, tracker=None):\n",
    "    thread = Thread(target=play_video, args=(video_path, canvas, label, tracker))\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "def track_multi_objects():\n",
    "    input_path = input_path_var.get()\n",
    "    if not input_path:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a video and process it first.\")\n",
    "        return\n",
    "\n",
    "    if detections is None or len(detections) == 0:\n",
    "        messagebox.showerror(\"Error\", \"No detections to track. Run detection first.\")\n",
    "        return\n",
    "\n",
    "    # Get current confidence threshold\n",
    "    confidence_threshold = get_confidence_threshold()\n",
    "\n",
    "    # Filter detections based on the confidence threshold and model type\n",
    "    if current_model == \"yolov5\":\n",
    "        valid_detections = [d for d in detections if d[4] > confidence_threshold]\n",
    "        confidence_scores = [d[4] for d in valid_detections]\n",
    "    elif current_model == \"yolov8\":\n",
    "        valid_detections = [(box, conf, cls) for box, conf, cls in detections if conf > confidence_threshold]\n",
    "        confidence_scores = [conf for _, conf, _ in valid_detections]\n",
    "    elif current_model == \"mask_rcnn\":\n",
    "        valid_detections = [(box, score) for box, score in detections if score > confidence_threshold]\n",
    "        confidence_scores = [score for _, score in valid_detections]\n",
    "\n",
    "    if not valid_detections:\n",
    "        messagebox.showerror(\"Error\", f\"No valid detections above confidence threshold of {confidence_threshold:.1%}\")\n",
    "        return\n",
    "\n",
    "    # Sort detections by confidence score in descending order\n",
    "    valid_detections = [x for _, x in sorted(zip(confidence_scores, valid_detections), reverse=True)]\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        messagebox.showerror(\"Error\", \"Failed to read video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Display detected objects with confidence scores\n",
    "    confidence_info = \"\\n\".join([f\"Object {i}: {confidence_scores[i]:.1%}\" for i in range(len(valid_detections))])\n",
    "    object_ids = simpledialog.askstring(\"Select Objects\", \n",
    "                                        f\"Enter object IDs separated by commas (or 'all' for tracking all objects):\\n\\n\"\n",
    "                                        f\"Detected objects (sorted by confidence):\\n{confidence_info}\")\n",
    "\n",
    "    if object_ids is None:\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    object_ids = object_ids.strip().lower()\n",
    "    if object_ids == 'all':\n",
    "        selected_indices = range(len(valid_detections))\n",
    "    else:\n",
    "        try:\n",
    "            selected_indices = [int(i) for i in object_ids.split(',') if 0 <= int(i) < len(valid_detections)]\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Invalid object IDs entered.\")\n",
    "            cap.release()\n",
    "            return\n",
    "\n",
    "    trackers = []\n",
    "    for i in selected_indices:\n",
    "        if current_model == \"yolov5\":\n",
    "            x1, y1, x2, y2, _, _ = valid_detections[i].tolist()\n",
    "        elif current_model == \"yolov8\":\n",
    "            box, _, _ = valid_detections[i]\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "        elif current_model == \"mask_rcnn\":\n",
    "            box, _ = valid_detections[i]\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        bbox = (int(x1), int(y1), int(x2 - x1), int(y2 - y1))\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        tracker.init(frame, bbox)\n",
    "        trackers.append(tracker)\n",
    "\n",
    "    display_multi_video(input_path, output_canvas, output_label, trackers)\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def display_multi_video(video_path, canvas, label, tracker=None):\n",
    "    thread = Thread(target=play_multi_video, args=(video_path, canvas, label, tracker))\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "# Initialize GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Object Detection Tool\")\n",
    "# root.geometry(\"2000x2000\")\n",
    "def toggle_fullscreen(event):\n",
    "    root.attributes('-fullscreen', not root.attributes('-fullscreen'))\n",
    "\n",
    "root.bind('<Escape>', toggle_fullscreen)\n",
    "\n",
    "# Add a variable to store the state of the checkbox\n",
    "show_confidence_var = tk.BooleanVar(value=False)  # Default to not showing confidence scores\n",
    "\n",
    "input_path_var = tk.StringVar()\n",
    "detections = None\n",
    "current_model = None\n",
    "\n",
    "# Welcome label\n",
    "welcome_label = tk.Label(root, text=\"Welcome to Object Detection Tool!\", font=(\"Helvetica\", 30))\n",
    "welcome_label.pack(pady=20)\n",
    "\n",
    "# Upload button\n",
    "upload_button = tk.Button(root, text=\"Upload Video\", font=(\"Helvetica\", 27), command=upload_video, fg=\"red\")\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Video display frames\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=20)\n",
    "\n",
    "input_label = tk.Label(frame, text=\"Input Video\", font=(\"Helvetica\", 25))\n",
    "input_label.grid(row=0, column=0, padx=20)\n",
    "\n",
    "detection_label = tk.Label(frame, text=\"Detection Candidates\", font=(\"Helvetica\", 25))\n",
    "detection_label.grid(row=0, column=1, padx=20)\n",
    "\n",
    "output_label = tk.Label(frame, text=\"Output Video\", font=(\"Helvetica\", 25))\n",
    "output_label.grid(row=0, column=2, padx=20)\n",
    "\n",
    "input_canvas = tk.Canvas(frame, width=460, height=270, bg=\"black\")\n",
    "input_canvas.grid(row=1, column=0, padx=20, pady=20)\n",
    "\n",
    "detection_canvas = tk.Canvas(frame, width=460, height=270, bg=\"black\")\n",
    "detection_canvas.grid(row=1, column=1, padx=20, pady=20)\n",
    "\n",
    "output_canvas = tk.Canvas(frame, width=460, height=270, bg=\"black\")\n",
    "output_canvas.grid(row=1, column=2, padx=20, pady=20)\n",
    "\n",
    "# YOLO buttons frame\n",
    "yolo_buttons_frame = tk.Frame(frame)\n",
    "yolo_buttons_frame.grid(row=2, column=0, pady=10)\n",
    "\n",
    "# Two YOLO buttons stacked vertically\n",
    "yolov5_button = tk.Button(yolo_buttons_frame, text=\"Run YOLOv5\", font=(\"Helvetica\", 18), command=process_with_yolov5, fg=\"red\")\n",
    "yolov5_button.pack(pady=5)\n",
    "\n",
    "yolov8_button = tk.Button(yolo_buttons_frame, text=\"Run YOLOv8\", font=(\"Helvetica\", 18), command=process_with_yolov8, fg=\"red\")\n",
    "yolov8_button.pack(pady=5)\n",
    "\n",
    "# Add Mask R-CNN button\n",
    "mask_rcnn_button = tk.Button(yolo_buttons_frame, text=\"Run Mask R-CNN\", font=(\"Helvetica\", 18), command=process_with_mask_rcnn, fg=\"red\")\n",
    "mask_rcnn_button.pack(pady=5)\n",
    "\n",
    "# checkbox\n",
    "confidence_checkbox = tk.Checkbutton(frame, text=\"Show Confidence Scores\", font=(\"Helvetica\", 14), variable=show_confidence_var, command=lambda: update_detection_frame(None, detections, current_model) if detections else None)\n",
    "confidence_checkbox.grid(row=2, column=1, pady=10)\n",
    "confidence_checkbox.grid(row=2, column=1, sticky=\"n\", pady=10)\n",
    "\n",
    "\n",
    "## cofidence search box\n",
    "\n",
    "# Create confidence score frame\n",
    "confidence_frame = tk.Frame(frame)\n",
    "confidence_frame.grid(row=3, column=0, pady=10)\n",
    "\n",
    "# Create and pack the label\n",
    "confidence_label = tk.Label(\n",
    "    confidence_frame,\n",
    "    text=\"Enter confidence threshold (0-100%):\",\n",
    "    font=(\"Helvetica\", 14)\n",
    ")\n",
    "confidence_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Register the validation command\n",
    "vcmd = (confidence_frame.register(validate_confidence_input), '%P')\n",
    "\n",
    "# Create and pack the entry widget\n",
    "confidence_entry = tk.Entry(\n",
    "    confidence_frame,\n",
    "    font=(\"Helvetica\", 14),\n",
    "    width=3,\n",
    "    validate='key',\n",
    "    validatecommand=vcmd\n",
    ")\n",
    "confidence_entry.pack(side=tk.LEFT, padx=(5, 10))  # Add some horizontal padding\n",
    "confidence_entry.insert(0, \"70\")  # Default value\n",
    "\n",
    "# Create apply button\n",
    "apply_button = tk.Button(\n",
    "    confidence_frame,\n",
    "    text=\"Apply\",\n",
    "    font=(\"Helvetica\", 14),\n",
    "    command=on_confidence_change,\n",
    "    fg=\"red\"\n",
    ")\n",
    "apply_button.pack(side=tk.LEFT)\n",
    "\n",
    "# Bind Enter key to the entry widget\n",
    "confidence_entry.bind('<Return>', on_confidence_change)\n",
    "\n",
    "# If you want to place it at specific coordinates\n",
    "confidence_frame.grid(row=2, column=1, pady=10)\n",
    "\n",
    "# Function to get the current confidence value (can be called from other parts of your code)\n",
    "def get_confidence_threshold():\n",
    "    try:\n",
    "        return float(confidence_entry.get()) / 100.0  # Convert to 0-1 range\n",
    "    except ValueError:\n",
    "        return 0.5  # Default value if invalid\n",
    "\n",
    "# Track object button\n",
    "track_button = tk.Button(frame, text=\"Track Object\", font=(\"Helvetica\", 18), command=track_object, fg=\"red\")\n",
    "track_button.grid(row=2, column=2, sticky=\"n\", pady=10)\n",
    "\n",
    "# Track multi objects button\n",
    "track_button = tk.Button(frame, text=\"Track Multi Objects\", font=(\"Helvetica\", 18), command=track_multi_objects, fg=\"red\")\n",
    "track_button.grid(row=2, column=2, pady=10)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
